import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
import speech_recognition as sr
import pyttsx3
import av
import numpy as np
from datetime import datetime
import logging
import openai
from dataclasses import dataclass
from typing import Optional, Dict, List, Any
import queue
import threading
import sounddevice as sd

# ログ設定
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


# 音声設定
@dataclass
class 音声設定:
    サンプルレート: int = 16000
    チャンクサイズ: int = 1024
    タイムアウト: float = 2.0
    言語: str = "ja-JP"


class 音声認識:
    def __init__(self, 設定: 音声設定 = 音声設定()):
        self.recognizer = sr.Recognizer()
        self.設定 = 設定
        self.認識中 = False
        self.音声キュー = queue.Queue()
        self._認識器設定()

    def _認識器設定(self):
        # 音声認識の感度を調整
        self.recognizer.energy_threshold = 3000
        self.recognizer.dynamic_energy_threshold = True
        self.recognizer.pause_threshold = 1.0

    def 認識開始(self):
        if not self.認識中:
            self.認識中 = True
            threading.Thread(target=self._認識スレッド, daemon=True).start()

    def 認識停止(self):
        self.認識中 = False

    def _認識スレッド(self):
        try:
            with sr.Microphone(sample_rate=self.設定.サンプルレート) as source:
                logger.info("周辺ノイズを調整中...")
                self.recognizer.adjust_for_ambient_noise(source, duration=2)
                logger.info("音声認識を開始しました")

                while self.認識中:
                    try:
                        audio = self.recognizer.listen(
                            source, timeout=self.設定.タイムアウト
                        )
                        text = self.recognizer.recognize_google(
                            audio, language=self.設定.言語
                        )
                        logger.info(f"認識結果: {text}")
                        self.音声キュー.put(text)
                    except sr.WaitTimeoutError:
                        continue
                    except sr.UnknownValueError:
                        logger.info("音声を認識できませんでした")
                    except Exception as e:
                        logger.error(f"音声認識エラー: {str(e)}")

        except Exception as e:
            logger.error(f"認識スレッドエラー: {str(e)}")
            self.認識中 = False


# 音声合成設定
@dataclass
class 音声合成設定:
    速度: int = 150
    音量: float = 1.0
    声種: str = "japanese"


class 音声合成:
    def __init__(self, 設定: 音声合成設定 = 音声合成設定()):
        self.engine = pyttsx3.init()
        self._合成器設定(設定)

    def _合成器設定(self, 設定: 音声合成設定):
        self.engine.setProperty("rate", 設定.速度)
        self.engine.setProperty("volume", 設定.音量)
        voices = self.engine.getProperty("voices")
        for voice in voices:
            if 設定.声種 in voice.name.lower():
                self.engine.setProperty("voice", voice.id)
                break

    def テキスト読み上げ(self, テキスト: str):
        try:
            self.engine.say(テキスト)
            self.engine.runAndWait()
        except Exception as e:
            logger.error(f"音声合成エラー: {str(e)}")


def main():
    st.title("音声チャット & 画面共有アプリケーション")

    # セッション状態の初期化
    if "音声認識" not in st.session_state:
        st.session_state.音声認識 = 音声認識()
    if "音声合成" not in st.session_state:
        st.session_state.音声合成 = 音声合成()

    # APIキー入力
    api_key = st.text_input("OpenAI APIキーを入力してください", type="password")
    if not api_key:
        st.warning("OpenAI APIキーが必要です")
        return

    # 音声認識コントロール
    col1, col2 = st.columns(2)
    with col1:
        if st.button("音声認識開始"):
            st.session_state.音声認識.認識開始()
            st.success("音声認識を開始しました")

    with col2:
        if st.button("音声認識停止"):
            st.session_state.音声認識.認識停止()
            st.info("音声認識を停止しました")

    # 認識テキストの表示と応答生成
    try:
        if not st.session_state.音声認識.音声キュー.empty():
            認識テキスト = st.session_state.音声認識.音声キュー.get()
            st.write(f"認識されたテキスト: {認識テキスト}")

            # OpenAIによる応答生成
            client = openai.OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[{"role": "user", "content": 認識テキスト}],
            )
            アシスタント応答 = response.choices[0].message.content
            st.write(f"アシスタントの応答: {アシスタント応答}")

            # ステータス表示
            ステータス = "録音中..." if st.session_state.音声認識.認識中 else "停止中"
            st.sidebar.write(f"ステータス: {ステータス}")
    except Exception as e:
        st.error(f"エラーが発生しました: {str(e)}")


if __name__ == "__main__":
    main()
