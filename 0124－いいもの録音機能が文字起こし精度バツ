import streamlit as st
import speech_recognition as sr
import queue
import threading
from datetime import datetime
import os

# Streamlitã‚¢ãƒ—ãƒªã®è¨­å®š
# - ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚¢ã‚¤ã‚³ãƒ³ã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
st.set_page_config(
    page_title="Instant Transcription App",
    page_icon="ğŸ’¬",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ã‚«ã‚¹ã‚¿ãƒ CSSã§ã‚¢ãƒ—ãƒªã®ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
# - ãƒ”ãƒ³ã‚¯ç³»ã®èƒŒæ™¯è‰²
# - ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°
st.markdown(
    """
<style>
.stApp { background-color: #FFF0F5; }
.stButton>button { 
    background-color: #FF69B4; 
    color: white; 
    border: none; 
}
.stTextArea {
    background-color: #FFE4E1;
    color: #8B008B;
}
</style>
""",
    unsafe_allow_html=True,
)


class VoiceRecognition:
    def __init__(self):
        # éŸ³å£°èªè­˜ã®åˆæœŸè¨­å®š
        # - éŸ³å£°èªè­˜ç”¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæº–å‚™
        # - éŸ³å£°ã‚­ãƒ¥ãƒ¼ã®åˆæœŸåŒ–
        # - éŒ²éŸ³ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆ
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        self.voice_queue = queue.Queue()
        self.is_recording = False
        self.recognition_thread = None
        os.makedirs("recordings", exist_ok=True)

    def _recognition_thread(self):
        # éŸ³å£°èªè­˜ã®ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰
        # - ç¶™ç¶šçš„ã«éŸ³å£°ã‚’ listening
        # - éŸ³å£°ã‚’ text ã«å¤‰æ›
        # - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        try:
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=2)
                while self.is_recording:
                    try:
                        audio = self.recognizer.listen(source, timeout=2.0)

                        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        audio_path = f"recordings/recording_{timestamp}.wav"
                        with open(audio_path, "wb") as f:
                            f.write(audio.get_wav_data())

                        # éŸ³å£°èªè­˜
                        text = self.recognizer.recognize_google(audio, language="ja-JP")
                        self.voice_queue.put((text, audio_path))
                    except sr.WaitTimeoutError:
                        continue
                    except sr.UnknownValueError:
                        st.warning("Could not understand audio")
                    except Exception as e:
                        st.error(f"Voice recognition error: {str(e)}")
        except Exception as e:
            st.error(f"Recognition thread error: {str(e)}")
            self.is_recording = False

    def start_recognition(self):
        # éŸ³å£°èªè­˜ã®é–‹å§‹
        # - ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä½œæˆã—ã¦éŸ³å£°èªè­˜ã‚’é–‹å§‹
        if not self.is_recording:
            self.is_recording = True
            self.recognition_thread = threading.Thread(
                target=self._recognition_thread, daemon=True
            )
            self.recognition_thread.start()

    def stop_recognition(self):
        # éŸ³å£°èªè­˜ã®åœæ­¢
        # - ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢
        self.is_recording = False
        if self.recognition_thread:
            self.recognition_thread.join()


def main():
    st.title("ğŸ’– Instant Transcription App")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ç®¡ç†
    # - éŸ³å£°èªè­˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
    if "voice_recognition" not in st.session_state:
        st.session_state.voice_recognition = VoiceRecognition()

    # çµæœè¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
    transcription_placeholder = st.empty()
    audio_placeholder = st.empty()

    # éŸ³å£°èªè­˜ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ¤ Start Recognition"):
            st.session_state.voice_recognition.start_recognition()
            st.success("Recognition started")

    with col2:
        if st.button("â¹ï¸ Stop Recognition"):
            st.session_state.voice_recognition.stop_recognition()
            st.info("Recognition stopped")

    # éŸ³å£°èªè­˜çµæœã®å‡¦ç†
    try:
        if not st.session_state.voice_recognition.voice_queue.empty():
            # æœ€æ–°ã®éŸ³å£°èªè­˜çµæœã‚’å–å¾—
            recognized_text, audio_path = (
                st.session_state.voice_recognition.voice_queue.get()
            )

            # çµæœã‚’ç”»é¢ã«è¡¨ç¤º
            transcription_placeholder.markdown(
                f"""
            ### ğŸ™ï¸ Transcription Result
            **Text:** {recognized_text}
            """
            )

            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ
            audio_placeholder.audio(audio_path)

    except Exception as e:
        st.error(f"An error occurred: {str(e)}")


if __name__ == "__main__":
    main()

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †:
# pip install streamlit speech_recognition
